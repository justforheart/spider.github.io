---
title: 爬虫远没我想的那么简单
layout: post
categories: 随笔
tags: 爬虫 不简单
---
这两天一直在看爬虫的入门教程，有些体会。
理论上所有的网站都是可以爬的，对于大多数数据挖掘robot.txt形同摆设。
好的网站都是追求格式一致，风格一致的统一管理和外观简洁。
差的网站也不可能全是自己写的（除非真的是有人闲的蛋疼做自己的网站，而且只有他自己维护），那种网站规模一般是最小的，爬虫都懒得去管，也没什么价值。
所以，基本上有价值的网站都是上规模的，都是需要严格管理的，等同于存在一定的规律。
而人的本质里都是懒得所有东西自己动手的，天下文章一大抄就是这么回事。
所以，基本上网站就几种设计模式或者说设计理念。
以上就是爬虫简单的地方。

有简单的地方，那就肯定存在着困难的地方。不然谷歌、百度靠什么吃饭的？
我们从小的说起，现在要下载一个页面的数据，很简单直接打开网页右键另存为，OK。
但是，我们普通人是不会看你什么<html><div>的，你把这些看不懂的东西去掉，这个时候你就要有点编程的东西了，你可能会用正则表达式去处理，可能用beautifulsoup、xpath、等等模块去处理。
当我们抽取出平常人都能看得懂，比较清晰的数据时，我们又发现，向首页啊、推荐啊、还有一大堆的广告，我是看的懂了，可是我看这个干嘛？
于是乎，我们得要对我们提取的数据进行筛选，这时 正则表达式就必不可少了，xpath或者beautifulsoup一通乱搞。
终于把有用的东西都筛出来了，这时，你肯定想爬虫可不是为了爬一个网页的技术，它可是能爬下整个网站、爬下整个Internet的存在啊，这也未免太大材小用了。
而且，一个页面得出的数据可以说没有丝毫价值（除非你爬的是NASA的机密文件^-^）。
我们又要撸起袖子，尝试着把这个页面相关的页面也爬下来，好的，我们决定先定个小目标，爬它100个页面。
没事，我们给他一个列表/数组、一个while或者for，搞定。你爬啊爬，虽然最后爬完了100页数据，但是也花了你N分钟，不应该啊，这么慢要想爬下整个网站那得要爬多久才行？
于是我们在网上查资料，原来我们的小程序都是小轱辘，爬得慢那是肯定的，于是我们决定也不换轮子了，直接整辆车给他换咯。我们一番比较，发现scrapy这个框架真的良心，基本上想要的功能集成了。
继续恶补scrapy知识，这个时候你才发现为什么程序员偏向于使用Linux，不是他们不玩游戏（当然可能也没时间玩），而是Linux上开发环境的配置基本上就是几行命令的事，到了windows下一顿操作猛如虎最后一看errors。
而且，商业性质的爬虫哪个不是在Linux上跑？我们还是乖乖的装个虚拟机吧。好不容易弄好了环境，终于可以上手打码了。真香！